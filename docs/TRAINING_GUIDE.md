# Guide d'Entra√Ænement du Mod√®le LSTM

## üìã Table des mati√®res
1. [D√©marrage rapide](#d√©marrage-rapide)
2. [Installation et pr√©requis](#installation-et-pr√©requis)
3. [Utilisation du script](#utilisation-du-script)
4. [Param√®tres et configurations](#param√®tres-et-configurations)
5. [Optimisations de performance](#optimisations-de-performance)
6. [R√©solution des probl√®mes](#r√©solution-des-probl√®mes)
7. [Pipeline complet](#pipeline-complet)

---

## üöÄ D√©marrage rapide

### Entra√Ænement simple
```bash
cd c:\Users\reppe\vscode_projet\Road2Million
python scripts/train_lstm.py --data data/raw/BTCUSDT-1m-2025-01.csv
```

### Entra√Ænement optimis√© (CUDA + Mixed Precision)
```bash
python scripts/train_lstm.py \
  --data data/raw/BTCUSDT-1m-2025-01.csv \
  --device cuda \
  --amp \
  --epochs 100 \
  --batch-size 128
```

---

## üîß Installation et pr√©requis

### 1. V√©rifier PyTorch
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

### 2. Si GPU CUDA (recommand√©)
```bash
# Pour CUDA 12.4 (recommand√©)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# V√©rifier l'installation
python -c "import torch; print(torch.cuda.is_available()); print(torch.cuda.get_device_name(0))"
```

### 3. D√©pendances
```bash
pip install pandas numpy scikit-learn joblib
```

---

## üìù Utilisation du script

### Syntax de base
```bash
python scripts/train_lstm.py [OPTIONS]
```

### Exemple complet avec tous les param√®tres
```bash
python scripts/train_lstm.py \
  --data data/raw/BTCUSDT-1m-2025-03.csv \
  --output-dir models/lstm \
  --epochs 150 \
  --batch-size 64 \
  --seq-length 60 \
  --hidden-size 128 \
  --num-layers 3 \
  --learning-rate 0.0005 \
  --device cuda \
  --amp \
  --warmup-epochs 5 \
  --dropout 0.3
```

---

## ‚öôÔ∏è Param√®tres et configurations

### Param√®tres obligatoires
| Param√®tre | Description | D√©faut |
|-----------|-------------|--------|
| `--data` | Chemin vers le CSV | `data/raw/BTCUSDT-1m-2025-01.csv` |

### Param√®tres d'entra√Ænement
| Param√®tre | Description | D√©faut | Recommand√© |
|-----------|-------------|--------|-----------|
| `--epochs` | Nombre d'√©pocas | 50 | 100-150 |
| `--batch-size` | Taille du batch | 32 | 64-256 (GPU) |
| `--learning-rate` | Taux d'apprentissage | 0.001 | 0.0005-0.001 |
| `--seq-length` | Longueur de s√©quence | 60 | 30-120 |
| `--dropout` | Taux dropout | 0.2 | 0.2-0.5 |

### Param√®tres du mod√®le
| Param√®tre | Description | D√©faut | Pour gros dataset |
|-----------|-------------|--------|------------------|
| `--hidden-size` | Couche cach√©e LSTM | 64 | 128-256 |
| `--num-layers` | Nombre couches LSTM | 2 | 2-4 |

### Param√®tres syst√®me
| Param√®tre | Description | Options |
|-----------|-------------|---------|
| `--device` | Device d'entra√Ænement | `cuda` (GPU), `cpu`, `auto` |
| `--amp` | Mixed Precision (‚ö° rapide) | Flag (ajouter pour activer) |
| `--output-dir` | Dossier de sortie | D√©faut: `models` |
| `--warmup-epochs` | Warmup learning rate | D√©faut: 5 |

---

## ‚ö° Optimisations de performance

### 1. **Mixed Precision (AMP)** - üèÜ Recommand√©
**Acc√©l√©ration: ~2x plus rapide | M√©moire: -50%**

Activer automatiquement:
```bash
python scripts/train_lstm.py --data ... --amp
```

- Compatible CUDA et CPU
- Perte de pr√©cision n√©gligeable
- R√©duit la m√©moire GPU de moiti√©

### 2. **Batch Size**
**Impact: Plus √©lev√© = plus rapide**

```bash
# CPU: 32-64
# GPU (6GB VRAM): 128-256
# GPU (12GB+ VRAM): 512-1024

python scripts/train_lstm.py --batch-size 256 --data ...
```

### 3. **Learning Rate Scheduling**
Le script utilise un **warmup lin√©aire** (5 √©pocas par d√©faut):
- √âpocas 0-4: LR augmente graduellement
- Apr√®s: LR d√©cro√Æt avec cosine annealing

```bash
python scripts/train_lstm.py --warmup-epochs 10 --data ...
```

### 4. **Device**
```bash
# Meilleur: GPU (CUDA)
python scripts/train_lstm.py --device cuda --data ...

# Fallback: CPU
python scripts/train_lstm.py --device cpu --data ...

# Auto-detect
python scripts/train_lstm.py --device auto --data ...
```

### 5. **Taille de donn√©es**
**Plus petit dataset = plus rapide**

```bash
# üü¢ Petit (entra√Ænement rapide)
--seq-length 30 --batch-size 256

# üü° Moyen
--seq-length 60 --batch-size 128

# üî¥ Gros (meilleure qualit√©, plus lent)
--seq-length 120 --batch-size 32
```

---

## üìä Temps d'entra√Ænement estim√©

### Configuration par machine

#### CPU Moderne (Intel i7/AMD Ryzen 7)
```
Dataset: 100K samples | Epochs: 50
Batch size: 32
‚è±Ô∏è Temps: 30-60 minutes
```

#### GPU (RTX 3060 / 6GB)
```
Dataset: 100K samples | Epochs: 50
Batch size: 128 | AMP: Activ√©
‚è±Ô∏è Temps: 3-5 minutes
```

#### GPU (RTX 4090 / 24GB)
```
Dataset: 100K samples | Epochs: 50
Batch size: 512 | AMP: Activ√©
‚è±Ô∏è Temps: <1 minute
```

---

## üìÅ Sorties de l'entra√Ænement

Apr√®s entra√Ænement, dans le dossier `models/`:

```
models/
‚îú‚îÄ‚îÄ lstm_btc_20260215_143022.pth           # Poids du mod√®le
‚îú‚îÄ‚îÄ lstm_btc_20260215_143022_scaler.pkl    # Normalisation (obligatoire)
‚îî‚îÄ‚îÄ lstm_btc_20260215_143022_config.json   # Configuration
```

### Fichier config.json
```json
{
  "input_size": 1,
  "hidden_size": 64,
  "num_layers": 2,
  "seq_length": 60,
  "features": ["Close"],
  "test_loss": 0.00234,
  "best_val_loss": 0.00198,
  "trained_on": "data/raw/BTCUSDT-1m-2025-01.csv",
  "timestamp": "20260215_143022"
}
```

---

## üîÑ Pipeline complet

### √âtape 1: Entra√Æner le mod√®le
```bash
python scripts/train_lstm.py \
  --data data/raw/BTCUSDT-1m-2025-03.csv \
  --epochs 100 \
  --batch-size 128 \
  --device cuda \
  --amp
```

**Output**: 3 fichiers dans `models/`

### √âtape 2: Tester le mod√®le
```python
from src.ia.price_predictor import PricePredictor

# Charger le mod√®le entra√Æn√©
predictor = PricePredictor(
    model_path="models/lstm_btc_20260215_143022.pth",
    scaler_path="models/lstm_btc_20260215_143022_scaler.pkl",
    config_path="models/lstm_btc_20260215_143022_config.json"
)

# Faire des pr√©dictions
prices = predictor.predict(sequence)
```

### √âtape 3: Int√©grer au bot
```python
from src.ia.price_predictor import PricePredictor
from src.strategies.sma_sentiment import SMASentimentStrategy

# Dans AlgBot.py
self.price_predictor = PricePredictor(
    model_path="models/lstm_btc_latest.pth",
    scaler_path="models/lstm_btc_latest_scaler.pkl",
    config_path="models/lstm_btc_latest_config.json"
)
```

---

## ‚ùì R√©solution des probl√®mes

### Erreur: "CUDA out of memory"
```bash
# R√©duire batch size
python scripts/train_lstm.py --batch-size 32 --device cuda --data ...

# Ou utiliser CPU
python scripts/train_lstm.py --device cpu --data ...

# Ou r√©duire seq_length
python scripts/train_lstm.py --seq-length 30 --data ...
```

### Erreur: "No module named 'lstm_models'"
```bash
# V√©rifier que lstm_models.py existe
ls src/ia/lstm_models.py

# Ajouter au path si n√©cessaire
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### Entra√Ænement tr√®s lent (CPU)
```bash
# Installer GPU PyTorch
pip install torch --index-url https://download.pytorch.org/whl/cu124

# Ou r√©duire la complexit√© du mod√®le
python scripts/train_lstm.py --hidden-size 32 --num-layers 1 --data ...
```

### Loss ne baisse pas
```bash
# R√©duire learning rate
python scripts/train_lstm.py --learning-rate 0.0001 --data ...

# Augmenter warmup
python scripts/train_lstm.py --warmup-epochs 10 --data ...

# V√©rifier les donn√©es
python scripts/view_raw_data.py data/raw/BTCUSDT-1m-2025-01.csv
```

---

## üéØ Recommandations

### Pour d√©buter (Testing)
```bash
python scripts/train_lstm.py \
  --data data/raw/BTCUSDT-1m-2025-01.csv \
  --epochs 20 \
  --batch-size 64 \
  --device auto
```

### Production (Haute qualit√©)
```bash
python scripts/train_lstm.py \
  --data data/raw/BTCUSDT-1m-2025-03.csv \
  --epochs 150 \
  --batch-size 256 \
  --hidden-size 256 \
  --num-layers 3 \
  --device cuda \
  --amp \
  --learning-rate 0.0003 \
  --warmup-epochs 10
```

### Production pour RTX4080s (Haute qualit√©)
python scripts/train_lstm.py \
  --data data/raw/BTCUSDT-1a-2025.csv \
  --epochs 150 \
  --batch-size 512 \
  --device cuda \
  --amp \
  --hidden-size 256 \
  --num-layers 3 \
  --seq-length 60 \
  --learning-rate 0.0003 \
  --warmup-epochs 10

### Ensemble Models (Meilleure pr√©cision)
```bash
# Entra√Æner 3-5 mod√®les avec diff√©rents seeds
for seed in {1..5}; do
  python scripts/train_lstm.py --data data/raw/BTCUSDT-1m-2025-03.csv --seed $seed
done
```

---

## üìö Ressources

- [PyTorch Documentation](https://pytorch.org/docs/)
- [Automatic Mixed Precision](https://pytorch.org/docs/stable/amp.html)
- [LSTM Best Practices](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
